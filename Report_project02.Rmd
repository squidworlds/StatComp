---
title: "Modelling Peak Electricity Demand in Great Britain"
author: "Group 50, Ella Park (s2311400), Saioa Galvin(s2516907),"
output:
  html_document:
    number_sections: no
  pdf_document:
    number_sections: no
header-includes:
  - \newcommand{\bm}[1]{\boldsymbol{#1}}
  - \newcommand{\mat}[1]{\begin{bmatrix}#1\end{bmatrix}}
---

```{r setup, include = FALSE}
# Set default code chunk options
knitr::opts_chunk$set(
  echo = TRUE,
  eval = TRUE
)

suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(numDeriv))
suppressPackageStartupMessages(library(mvtnorm))
suppressPackageStartupMessages(library(gridExtra))
suppressPackageStartupMessages(library(latex2exp))
suppressPackageStartupMessages(library(kableExtra))
suppressPackageStartupMessages(library(viridis))
theme_set(theme_bw(base_size = 9))

demand <- read.csv("SCS_demand_modelling.csv")

set.seed(12345L)
```

```{r reading_code, code=readLines("code.R"), eval=TRUE, echo=FALSE}
source("code.R")
```

# Introduction- brief

This section provides a brief introduction to the task and the datasets used. The introduction is intended to be understood by NESO analysts with a scientific background but limited statistical expertise. You can assume that the reader of your report has read the executive summary. Briefly outline the overall approach taken in modeling future daily peak electricity demand, describe the main steps involved, and summarize the key conclusions drawn from the analysis.

# Introduction- part completed

Accurately forecasting future daily peak electricity demand is crucial for NESO's (National Electricity System Operator) planning and security of supply analysis. High demand events in winter pose the greatest risk of electricity shortfalls since cold weather increases energy consumption, so we are is particularly interested in modelling the upper tail of the demand distribution so NESO can better anticipate extreme scenarios and allocate reserves efficiently.

The primary dataset used, `SCS_demand_modelling.csv`, contains historical daily peak electricity demand data for Great Britain, focusing on winter months. The data spans from 1st November 1991 to 31st March 2014. Each row represents a single day, describing electricity demand and capturing key factors that influence this including weather conditions and renewable energy generation.

In this report, we develop and evaluate a linear regression model to estimate future peak demand using historical electricity demand data and relevant explanatory variables, focusing on the winter months where there is highest risk. We begin with a baseline model $M_0$ incorporating key predictors such as wind and solar generation, temperature, and temporal factors. We then explore model refinements by incorporating additional covariates, considering adjustments for long-term trends and alternative temperature variables. In order to compare and select our best model, we discuss how well our model fits historic data, prediction accuracy and how peak demand varies under different weather conditions. To compare prediction accuracy, we construct a cross-validation scheme that computes prediction scores across months and then weekdays versus weekends.

The final model is selected based on predictive performance and interpretability, providing NESO with a reliable tool for demand forecasting. We also discuss the limitations of the model and highlight areas for further improvement to enhance its accuracy and robustness.

?THIS NEEDS IMPROVEMENTS- include key conclusions drawn

# Data description and exploratory analysis- Brief

Emphasis should be placed on the data features that are relevant for the subsequent modeling. Include visualizations that help illustrate key patterns or relationships. All plots must also be described in the write up. Think carefully about whether each plot needs to be included in your final draft. Your report should include figures and tables but they should be as focused and impactful as possible.

Clearly describe all preprocessing steps, including any transformations or new variables created. If the additional dataset (`SCS_hourly_temp.csv` ) is used, provide a concise explanation of its structure and relevance to the analysis.

# Data description and exploratory analysis- first draft

A thorough understanding of the dataset is essential for building an effective forecasting model. This section explores key features relevant to modelling, highlighting important patterns through visualizations to inform model development and summarizes the preprocessing? steps undertaken.

We begin by analyzing the continuous variables from our dataset and their relationship to peak electricity demand. The key predictors to explore are:

-   Response variables: demand_gross (MW)- Peak electricity demand

-   Explanatory variables:

    -   Weather factors: wind, solar_S, TE

    -   Temporal trends: year

```{r demand  scatters, echo=FALSE, warning=FALSE}
# Wind vs demand
wind_plot <- ggplot(demand, aes(x=wind, y=demand_gross)) +
  geom_point(alpha=0.5, color="darkgreen") +
  geom_smooth(method="lm", color="red") +
  labs(title="Peak Demand vs Wind Capacity Factor", x="Wind Capacity Factor", y="Peak Demand (MW)") +
  theme_bw()

# Solar vs demand
solar_plot <- ggplot(demand, aes(x=solar_S, y=demand_gross)) +
  geom_point(alpha=0.5, color="darkorange") +
  geom_smooth(method="lm", color="red") +
  labs(title="Peak Demand vs Solar Capacity Factor", x="Solar Capacity Factor", y="Peak Demand (MW)") +
  theme_bw()

# Temp vs demand- shows negative correlation
temp_plot <- ggplot(demand, aes(x=temp, y=demand_gross)) +
   geom_point(alpha=0.5, color="darkgoldenrod") +
   geom_smooth(method="lm", color="red") +
   labs(title="Peak Demand vs Temperature", x="Temperature (°C)", y="Peak Demand (MW)") +
   theme_bw()

# TE vs demand- shows negative correlation
te_plot <- ggplot(demand, aes(x=TE, y=demand_gross)) +
   geom_point(alpha=0.5, color="steelblue") +
   geom_smooth(method="lm", color="red") +
   labs(title="Peak Demand vs TE", x="Temperature (°C)", y="Peak Demand (MW)") +
   theme_bw()

# Year vs demand- shows negative correlation
year_plot <- ggplot(demand, aes(x=year, y=demand_gross)) +
   geom_point(alpha=0.5, color="darkmagenta") +
   geom_smooth(method="lm", color="red") +
   labs(title="Peak Demand vs Year", x="Year", y="Peak Demand (MW)") +
   theme_bw()

grid.arrange(wind_plot, solar_plot, temp_plot, te_plot, year_plot, ncol = 2)
```

The first plot is a scatter graph between the wind capacity factor and the daily peak electricity demand indicates a weak relationship, suggesting wind generation has only a minimal impact on peak demand. This is expected, as wind generation may not correlate strong with demand peaks, which are often influenced more by factors like temperature. In terms of modelling, the wind variable may not be a significant predictor and the regression coefficient is likely to be small. To analyse this, we check the coefficient and statistical significance in the p-value in our models (MAYBE INCLUDE VALUES?). Additionally, we use the $\texttt{step}$ function in R to perform backward stepwise regression. This method iteratively removes variables that variables that do not contribute significantly to the model, based on the Akaike Information Criterion (AIC). Later in this report, we see that wind is included in the final model, therefore the AIC does not improve upon its removal. This would indicate it holds some importance for predicting demand, even if the relationship is weak.

Solar ahhhh

Both the scatter plots of temperature and TE against demand gross show a negative correlation where higher temperatures generally correspond to a lower electricity demand. This relationship makes intuitive sense, as warmer temperatures tend to reduce the need for heating, which is a significant factor in electricity demand during colder months. Given the clear consistent negative correlation, it was important to include one temperature variable in the model.

Both temp and TE variables cannot be included in the model since they are based on very similar temperature data. Including both variables would introduce multicolliniarity which could affect the regression results so we only select one. TE shows slightly less variation in demand compared to temp which includes on temperature at 6pm that day. This is because TE includes data from the day before, effectively smoothing out the fluctuations in temperature and providing a more stable representation of the temperature's influence on demand. This smoothing effect should help the model to capture long term temperature trends better than temperature alone, as it captures the lag in temperatures effect on energy. This helps to provide the hypothesis that TE is a more valuable measure of temperature than the temp variable. Subsequent analysis will provide evidence to support this.

The plot between year and peak demand reveals a correlation, suggesting that demand increases over time. However from this it is evident the relationship is more complex than a simple linear trend, following a cubic pattern. This implies that the the effect of the year variable on demand is not constant and changes as time progresses. There are a variety of reasons which this occurs such as reflecting long-term trends in energy usage, economic growth, policy changes or technological advancements. The following graphs visualize this hypothesis to assess whether a quadratic or cubic term improves the model's fit compared to the linear one.

```{r exploring year, echo=FALSE, warning=FALSE}
year_quadratic <- ggplot(demand, aes(x=year, y=demand_gross)) +
   geom_point(alpha=0.5, color="darkcyan") +
   geom_smooth(method="lm", formula = y ~ poly(x, 2), color="red") +  
   labs(title="Peak Demand vs Year", x="Year", y="Peak Demand (MW)") +
  theme_bw()

year_cubic <- ggplot(demand, aes(x=year, y=demand_gross)) +
   geom_point(alpha=0.5, color="darkcyan") +
   geom_smooth(method="lm", formula = y ~ poly(x, 3), color="red") +  
   labs(title="Peak Demand vs Year", x="Year", y="Peak Demand (MW)") +
  theme_bw()

grid.arrange(year_quadratic, year_cubic, ncol = 2)
```

Next we investigate the effect of categorical on peak demand by analyzing its variation across different days of the week and months using violin plots.

```{r violin, echo=FALSE, warning=FALSE}
# Day of week
day_plot <- ggplot(demand, aes(x=factor(wdayindex), y=demand_gross, fill=factor(wdayindex))) +
  geom_violin(alpha=0.5) +  # Create the violin plot
  geom_boxplot(width=0.2, color="black", alpha=0.7) +  # Add a boxplot inside the violin for quartiles
  scale_fill_brewer(palette="Dark2") + 
  scale_x_discrete(labels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")) +
  labs(title="Peak Demand by Day of the Week", x="Day of Week", y="Peak Demand (MW)") +
  theme_bw() +
  guides(fill=FALSE) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Month vs demand
month_plot <- ggplot(demand, aes(x=factor(monthindex, levels = c(10, 11, 0, 1, 2)), y=demand_gross, fill=factor(monthindex))) +
  geom_violin(alpha=0.5) +  # Create the violin plot
  geom_boxplot(width=0.2, color="black", alpha=0.7) +  # Add a boxplot inside the violin for quartiles
  scale_fill_brewer(palette="Dark2") +  
  scale_x_discrete(labels=c("October", "November", "December", "Janurary", "February")) +
  labs(title="Peak Demand Distribution by Month", x="Month", y="Peak Demand (MW)") +
  theme_bw() +
  guides(fill=FALSE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(day_plot, month_plot, ncol = 2, nrow = 1)
```

The violin plot for day of the week reveals several key trends in peak electricity demand. The data shows that weekdays generally exhibit higher peak demand compared to weekends. This is consistent with the expectation that electricity consumption tends to be higher during working days due to office buildings and factories. This poses the question if we could simplify the model by grouping weekends together as a single category, thereby reducing the complexity while still capturing the key variation in demand on weekdays versus weekends. The following table allows us to analyse the differences numerically. 
```{r wday eda table, echo=TRUE}
weekdays_stats <- data.frame(
  Day = factor(0:6, labels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")),
  Median = tapply(demand$demand_gross, demand$wdayindex, median, na.rm = TRUE),
  Q1 = tapply(demand$demand_gross, demand$wdayindex, function(x) quantile(x, 0.25, na.rm = TRUE)),
  Q3 = tapply(demand$demand_gross, demand$wdayindex, function(x) quantile(x, 0.75, na.rm = TRUE))
)
kable(weekdays_stats, caption = "Median and Quartiles for Each Day of the Week", align = "c", format = "markdown")
```

Friday stands out with slightly lower peak demand compared to other weekdays. Its median is nearly 2,000 MW lower than the average of the other weekdays which could be attributed to reduced business activity as the weekend approaches. In terms of weekday behavior, there is considerable overlap between the days. The medians for these days are quite close, indicating that demand is fairly consistent throughout the workweek. When comparing weekdays to weekends, there is a clear difference in the median values. Weekdays have a higher median peak demand around 52,000, while weekends show lower values of 45,000.

Including day of the week as a factor variable in the model ensures that all variations in demand across different days are incorporated into the model. This allows the regression to account for differences in peak demand as well as any subtle variations between individual weekdays. This should help the model more effectively capture demand patterns without oversimplifying the structure of the data. These differences lead us to hypothesise that this variable will be useful in the model and statistically significant. Our later analysis will confirm this. 

The next step is to explore interactions that can help improve the model accuracy. Interactions allow us to capture relationships where the effect of one variable on peak demand depends on the value of another.

# Model fitting and cross-validation results

In this section you should detail your choice of model and describe the process used to refine and fit the model. You are encouraged to explore different models methods but you should not include a detailed narrative of all of these attempts. For instance, you can mention the approaches you tried tried and include a comparison but do not add in depth discussions of these models beyond why they were rejected. This section should mention the methods explored and why they were rejected, but most of your effort should go into describing the model you are using and your process for tuning and validating it.

Provide implementation details and include results from cross-validation or other model evaluation techniques, highlighting improvements and any trade-offs.

The model we are proposing is 

$$Gross Demand \sim wind + solar\_S + TE + daytype + month + start_year + start_year^2 + start_year^3 + \varepsilon,$$

where $daytype$ is a factor variable taking values "weekday" and "weekend", and month is a factor variable taking values "Nov", "Dec", "Jan", "Feb" and "Mar". This is important as we cannot consider month and day as continuous variables in the given dataset.

## Other Models Considered

Ella, would you be able to give more detail here about which models you were looking at please? e.g. how you chose the models you did.

Backward selection?

To evaluate the models to consider, the most important metrics to consider are the R-Squared and Adjusted R_Squared scores, as well as the AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion) [should we mention these?] and Root Mean Squared Error (RMSE). These metrics for each model are shown in the following table.

```{r comparing_models, warning = FALSE, echo=FALSE, out.width="50%", cache = FALSE}

# making daytype into a factor variable then taking out outliers
demand$daytype <- factor(
  ifelse(demand$wdayindex %in% 0:4, "Weekday", "Weekend"),
  levels = c("Weekday", "Weekend")
)
demand$month <- factor(demand$monthindex,
  levels = c(10, 11, 0, 1, 2), 
  labels = c("Nov", "Dec", "Jan", "Feb", "Mar")
)


# models we are considering
m0 <- lm(demand_gross ~ 1 + wind + solar_S + temp + wdayindex + monthindex, data = demand)
m0_year_cubed_te_squared <- lm(demand_gross ~ (1 + wind + solar_S + TE + daytype + month + poly(start_year, 3))^2, data = demand)
m0_daytype_outliers <- lm(demand_gross ~ 1 + wind + solar_S + temp + daytype + month, data = demand)
year_cubed_te_squared <- lm(demand_gross ~ (wind + solar_S + TE + I(daytype)^2 + month + poly(start_year, 3))^2, data = demand)
best <- lm(demand_gross ~ (1 + wind + solar_S + TE + I(daytype)^2 + poly(month, 3) + poly(start_year, 3))^2, data = demand)

# putting all these models into a vector for comparison
lms <- list(m0, m0_year_cubed_te_squared, m0_daytype_outliers, year_cubed_te_squared, best_no_outliers_sqr)
names <- c("m0", "Poly Year, TE, interactions", "m0, daytype factor, no outliers", "Poly Year, TE, interactions, no outliers", "final model")

# creating the comparison table
comparison_df <- comparison(lms, names, demand)
colnames(comparison_df) <- c("Model", "$\\R^2$", "Adjusted $R^2$", "AIC", "BIC")

```

```{r comparison_table, warning = FALSE, echo=TRUE, out.width="50%", cache = FALSE}
kable(comparison_df, format = "latex", caption = "Model Comparison Metrics", escape = FALSE) %>%
  kable_styling(latex_options = c("striped", "HOLD_position"))
```

The table above shows that... I want to do analysis of R^2 here but I will wait until we have our best model. Talk about what each metric means.

## Testing on Historical Data

As well as metrics, the validity of our model can be shown by testing on historical data.

```{r historical, warning = FALSE, echo=FALSE, out.width="50%", cache = FALSE}
# predicting for just m0 and our best model
m0_prediction <- lm_predicting(m0, demand)
m0_plot <- plotting(m0_prediction, demand)

best_prediction <- lm_predicting(best, demand)
best_plot <- plotting(best_prediction, demand)

# creating a dataset with predicted and actual data
m0_data <- cbind(m0_prediction, demand)
best_data <- cbind(best_prediction, demand)

# time?
# pick an explanatory variable

m0_historical_daytype <- ggplot(m0_data, aes(x = demand_gross, y = mean_pred, color = daytype)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = lm, se = TRUE) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  labs(
    title = "Modelling m0 For Historical Demand",  # Title
    x = "Actual Demand (Gross)",  # X-axis label
    y = "Predicted Demand (Mean)",  # Y-axis label
    color = "Day type"  # Color legend label
  )

best_historical_daytype <- ggplot(best_data, aes(x = demand_gross, y = mean_pred, color = daytype)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = lm, se = TRUE) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  labs(
    title = "Final Model For Historical Demand",  # Title
    x = "Actual Demand (Gross)",  # X-axis label
    y = "Predicted Demand (Mean)",  # Y-axis label
    color = "Day type"  # Color legend label
  )

m0_historical_month <- ggplot(m0_data, aes(x = demand_gross, y = mean_pred, color = month)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = lm, se = TRUE) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  labs(
    title = "Modelling m0 For Historical Demand",  # Title
    x = "Actual Demand (Gross)",  # X-axis label
    y = "Predicted Demand (Mean)",  # Y-axis label
    color = "Month"  # Color legend label
  )

best_historical_month <- ggplot(best_data, aes(x = demand_gross, y = mean_pred, color = month)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = lm, se = TRUE) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  labs(
    title = "Final Model For Historical Demand",  # Title
    x = "Actual Demand (Gross)",  # X-axis label
    y = "Predicted Demand (Mean)",  # Y-axis label
    color = "Month"  # Color legend label
  )
```

```{r historical_plot, warning = FALSE, echo = TRUE, out.width="100%", cache = FALSE}
grid.arrange(m0_historical_daytype, best_historical_daytype, m0_historical_month, best_historical_month, ncol = 2)
```

We'll want to include residuals plots here.

### Residuals


## Cross-Validation

Once we have tested on historical data, we can test the validity of our model by examining how well it predicts. One way of doing this is by performing cross-validation.

First, it is important to note that our dataset now has $daytype$ and $month$ as factor variables. We will perform leave-one-out cross-validation over months to compare how the model predicts in the different winter months that we are given. 

```{r loocv, warning = FALSE, echo=FALSE, out.width="50%", cache = FALSE}
source("code.R")
m0_formula <- demand_gross ~ 1 + wind + solar_S + temp + wdayindex + monthindex
m0_scores <- monthly_rolling_model(demand, m0_formula)
m0_scores$model <- "m0"

best_formula <- demand_gross ~ (1 + wind + solar_S + TE + I(daytype)^2 + poly(month, 3) + poly(year, 3))^2
best_scores <- monthly_rolling_model(demand, best_formula)
best_scores$model <- "best"

all_scores <- rbind(m0_scores, best_scores)

m0_sample <- all_scores %>%
  filter(model == "m0") %>%     # Filter for 'm0' model
  sample_n(5, replace = FALSE)

best_sample <- all_scores %>%
  filter(model == "best") %>%   # Filter for 'best' model
  sample_n(5, replace = FALSE)

combined_sample <- rbind(m0_sample, best_sample) %>%
  arrange(model, year, month) %>%
  group_by(model)
```

```{r scores_table, warning = FALSE, echo=TRUE, out.width="50%", cache = FALSE}
kable(combined_sample)
```

Do some score analysis here, check out tutorials 7,9,10 and lecture 7 slides.

We can also examine graphs.

```{r reg_plotting,  warning = FALSE, echo=FALSE, out.width="50%", cache = FALSE}
# plotting actual and mean vs month for a single model at a time
reg_plot <- ggplot(all_scores, aes(x = actual, y = mean, color = model)) +
  geom_point(alpha = 0.4) +                      # Scatter plot of actual vs predicted
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +  # Line y=x for reference
  facet_wrap(~month) +
  labs(
    title = "Actual vs Predicted Demand",
    x = "Actual Demand",
    y = "Predicted Demand",
    color = "Model"
    )


```

```{r reg_plot, warning = FALSE, echo=TRUE, cache = FALSE}
reg_plot
```

This is not a very good plot because there are some very far away points... what's going on?

```{r scores_plotting,  warning = FALSE, echo=FALSE, out.width="50%", cache = FALSE}
se_plot <- ggplot(all_scores, aes(
  x = actual, 
  y = se, 
  color = model
  )) +
geom_point()

ds_plot <- ggplot(all_scores, aes(
  x = actual, 
  y = ds, 
  color = model
  )) +
geom_point()
```

```{r scores_plot, warning = FALSE, echo = TRUE, cache = FALSE}
grid.arrange(se_plot, ds_plot, ncol = 2)
```

## Exchangeability Test

``` {r exchange, warning = FALSE, echo=FALSE, out.width="50%", cache = FALSE}

# create a dataframe to find the difference between scores for different models

score_diff <- all_scores %>%
  filter(model %in% c("m0", "best")) %>%        # Filter for model1 and model2
  pivot_wider(names_from = model, values_from = c(se, ds)) %>%  # Reshape the data (se and ds for model1 and model2 in separate columns)
  mutate(
    se = se_m0 - se_best,  # Calculate the difference for se
    ds = ds_m0 - ds_best   # Calculate the difference for ds
  )

statistic0 <- score_diff %>% 
  summarise(se = mean(se), 
            ds = mean(ds))


# number of iterations
J <- 10000

# initialise dataframe
statistic <- data.frame(se = numeric(J),
                        ds = numeric(J))

# loop over randomisation samples
for (loop in seq_len(J)) {
  
  # sample random sign changes
  random_sign <- sample(c(-1, 1), 
                        size = nrow(score_diff), 
                        replace = TRUE)
  
  statistic[loop, ] <- score_diff %>% 
    summarise(se = mean(random_sign * se),
              ds = mean(random_sign * ds))
}

# now find the p values
p_values <- statistic %>%
  summarise(se = mean(se > statistic0$se),
            ds = mean(ds > statistic0$ds))

# Estimates:
p_values

```

# Conslusion

Summarize here the key insights from your analysis, focusing on the final model’s predictive performance, reliability, and practical relevance for NESO. Discuss the importance of the selected covariates, as well as any observed limitations or assumptions that should be considered when applying the model in practice.

Emphasize how your model can support NESO's long-term planning goals. If the model underperforms in some respects, provide a clear and well-reasoned explanation. Keep in mind that a negative result, i.e. a model that does not work well predictively, that is well explained and justified in terms of why it failed will likely receive higher marks than a model with strong predictive performance but with poor or incorrect explanations and justifications. In other words, sound reasoning and transparency will be valued more than overclaiming results.

# Code Appendix

Include here all the code used in your analysis. Ensure that the code is well-commented so it is easy to follow and reuse.

```{r code=readLines("code.R"), eval=FALSE, echo=TRUE}
# Do not change this code chunk
```

